"""
Pneumonia Detection from Chest X-Ray Images using CNN
This program trains a convolutional neural network to classify chest X-rays 
as either NORMAL or PNEUMONIA.
"""

# Install required package (run in terminal):
# pip install opencv-python

import numpy as np
import cv2
import os
import matplotlib.pyplot as plt
try:
    import seaborn as sns
    HAS_SEABORN = True
except ModuleNotFoundError:
    HAS_SEABORN = False
    print("Warning: seaborn is not installed; using matplotlib only for plots.")
import tensorflow as tf
from tensorflow.keras.layers import Input, Flatten, Conv2D, Activation, Dense, Dropout, MaxPooling2D
from tensorflow.keras.models import Sequential, model_from_json

# (pickle is no longer needed for model export once we use .keras/.tflite)

# Configuration
IMG_SIZE = 256
labels = ["NORMAL", "PNEUMONIA"]

# Directory paths
train_folder = "chest_xray/train"
test_folder = "chest_xray/test"
val_folder = "chest_xray/val"

def get_data(data_dir):
    """
    Load and preprocess image data from directory
    
    Args:
        data_dir: Path to data directory containing NORMAL and PNEUMONIA folders
    
    Returns:
        numpy array containing [image_array, class_label] pairs
    """
    data = []
    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif')
    for label in labels:
        path = os.path.join(data_dir, label)
        if not os.path.exists(path):
            print(f"Warning: Directory {path} does not exist. Skipping...")
            continue
        class_num = labels.index(label)
        for img in os.listdir(path):
            if img.lower().endswith(image_extensions):
                try:
                    img_path = os.path.join(path, img)
                    img_array = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
                    if img_array is not None:
                        new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
                        data.append([new_array, class_num])
                    else:
                        print(f"Warning: Could not read image {img}")
                except Exception as e:
                    print(f"Error loading {img}: {e}")
    return np.array(data, dtype=object)

# Load datasets
print("Loading training data...")
train = get_data(train_folder)
print(f"Loaded {len(train)} training samples")
print("Loading test data...")
test = get_data(test_folder)
print(f"Loaded {len(test)} test samples")
print("Loading validation data...")
val = get_data(val_folder)
print(f"Loaded {len(val)} validation samples")

# Check if datasets are empty
if len(train) == 0:
    raise ValueError("Training dataset is empty! Please check the data directory.")
if len(test) == 0:
    raise ValueError("Test dataset is empty! Please check the data directory.")
if len(val) == 0:
    print("Warning: Validation dataset is empty. Consider using a portion of training data for validation.")

# Visualize class distribution
print("\nVisualizing class distribution...")
l = ["Normal" if i[1] == 0 else "Pneumonia" for i in train]
plt.figure(figsize=(8, 6))
if HAS_SEABORN:
    sns.countplot(x=l)
else:
    from collections import Counter
    counts = Counter(l)
    plt.bar(list(counts.keys()), list(counts.values()))
plt.title("Training Data Distribution")
plt.show()

# Prepare training data
X_train = []
y_train = []
for feature, label in train:
    X_train.append(feature)
    y_train.append(label)

# Prepare test data
X_test = []
y_test = []
for feature, label in test:
    X_test.append(feature)
    y_test.append(label)

# Prepare validation data
X_val = []
y_val = []
for feature, label in val:
    X_val.append(feature)
    y_val.append(label)

# Normalize pixel values to [0, 1]
X_train = np.array(X_train) / 255.0
X_val = np.array(X_val) / 255.0
X_test = np.array(X_test) / 255.0

# Reshape for CNN input (samples, height, width, channels)
X_train = X_train.reshape(-1, IMG_SIZE, IMG_SIZE, 1)
y_train = np.array(y_train)

X_val = X_val.reshape(-1, IMG_SIZE, IMG_SIZE, 1)
y_val = np.array(y_val)

X_test = X_test.reshape(-1, IMG_SIZE, IMG_SIZE, 1)
y_test = np.array(y_test)

print(f"\nData shapes:")
print(f"X_train: {X_train.shape}, y_train: {y_train.shape}")
print(f"X_val: {X_val.shape}, y_val: {y_val.shape}")
print(f"X_test: {X_test.shape}, y_test: {y_test.shape}")

# Build CNN Model
print("\nBuilding CNN model...")
model = Sequential([
    # Input layer
    Input(shape=X_train.shape[1:]),
    
    # First convolutional block
    Conv2D(32, (3, 3), padding="same"),
    Activation("relu"),
    MaxPooling2D(2, 2),
    Dropout(0.2),
    
    # Second convolutional block
    Conv2D(64, (3, 3), padding="same"),
    Activation("relu"),
    MaxPooling2D(2, 2),
    Dropout(0.5),
    
    # Third convolutional block
    Conv2D(128, (3, 3), padding="same"),
    Activation("relu"),
    MaxPooling2D(2, 2),
    Dropout(0.2),
    
    # Fourth convolutional block
    Conv2D(256, (3, 3), padding="same"),
    Activation("relu"),
    MaxPooling2D(2, 2),
    Dropout(0.2),
    
    # Fully connected layers
    Flatten(),
    Dense(256, activation="relu"),
    Dense(1, activation="sigmoid")
])

# Compile model
callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
opt = tf.keras.optimizers.Adam(learning_rate=1e-5)
model.compile(loss="binary_crossentropy", optimizer=opt, metrics=["accuracy"])

model.summary()

# Train model
print("\nTraining model...")
history = model.fit(
    X_train, y_train, 
    epochs=50, 
    validation_data=(X_val, y_val), 
    shuffle=True, 
    callbacks=[callback]
)

# Evaluate model
print("\nEvaluating model on test data...")
scores = model.evaluate(X_test, y_test)
print(f"Test loss: {scores[0]:.4f}")
print(f"Test accuracy: {scores[1]:.4f}")

# Save model in Keras format (smaller + portable)
model.save("cnn_model.keras")
print("\nModel saved as 'cnn_model.keras'")

# Export an even smaller TFLite model (float16 quantization)
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]

tflite_model = converter.convert()
with open("cnn_model.tflite", "wb") as f:
    f.write(tflite_model)
print("Exported 'cnn_model.tflite' (float16 quantized)")

# Visualize training history
print("\nGenerating training visualizations...")
accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(accuracy))

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(epochs, accuracy, "b", label="Training accuracy")
plt.plot(epochs, val_accuracy, "r", label="Validation accuracy")
plt.title("Training and Validation Accuracy")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(epochs, loss, "b", label="Training loss")
plt.plot(epochs, val_loss, "r", label="Validation loss")
plt.title("Training and Validation Loss")
plt.legend()

plt.tight_layout()
plt.show()

# Make predictions
print("\nMaking predictions on test data...")
predictions = (model.predict(X_test) > 0.5).astype(int).reshape(-1)

# Find correct and incorrect predictions
correct = np.nonzero(predictions == y_test)[0]
incorrect = np.nonzero(predictions != y_test)[0]

print(f"Correct predictions: {len(correct)}")
print(f"Incorrect predictions: {len(incorrect)}")

# Visualize correct predictions
plt.figure(figsize=(10, 12))
for j, i in enumerate(correct[:6]):
    plt.subplot(3, 2, j+1)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(X_test[i].reshape(256, 256), cmap="gray", interpolation='none')
    plt.title(f"Predicted: {labels[predictions[i]]}, Actual: {labels[y_test[i]]}")
    plt.xlabel(labels[predictions[i]])
plt.suptitle("Correct Predictions")
plt.tight_layout()
plt.show()

# Visualize incorrect predictions
if len(incorrect) > 0:
    plt.figure(figsize=(10, 12))
    for j, i in enumerate(incorrect[:6]):
        plt.subplot(3, 2, j+1)
        plt.xticks([])
        plt.yticks([])
        plt.imshow(X_test[i].reshape(256, 256), cmap="gray", interpolation='none')
        plt.title(f"Predicted: {labels[predictions[i]]}, Actual: {labels[y_test[i]]}")
        plt.xlabel(labels[predictions[i]])
    plt.suptitle("Incorrect Predictions")
    plt.tight_layout()
    plt.show()

# Function to prepare external images for prediction
def prepare(filepath):
    """
    Prepare an external image for prediction
    
    Args:
        filepath: Path to image file
    
    Returns:
        Preprocessed image array ready for model prediction
    """
    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)
    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
    normalized = new_array / 255.0
    return normalized.reshape(-1, IMG_SIZE, IMG_SIZE, 1)

# Example: Load model and predict on new images
print("\n=== Prediction on External Images ===")
print("To predict on a new image, use:")
print("prediction = model.predict([prepare('path/to/image.jpg')])")
print("result = labels[int(prediction[0] > 0.5)]")
print("print(f'Prediction: {result}')")

# Uncomment below to test on external images:
"""
# Load saved model (.keras)
model = tf.keras.models.load_model("cnn_model.keras")

# Predict on external images
prediction = model.predict([prepare("path/to/pneumonia_image.jpg")])
print(f"Prediction: {labels[int(prediction[0] > 0.5)]}")

prediction = model.predict([prepare("path/to/normal_image.jpg")])
print(f"Prediction: {labels[int(prediction[0] > 0.5)]}")
"""
